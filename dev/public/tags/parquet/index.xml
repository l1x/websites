<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>parquet on l1x/dev</title><link>https://dev.l1x.be/tags/parquet/</link><description>Recent content in parquet on l1x/dev</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 08 Mar 2021 20:38:21 +0100</lastBuildDate><atom:link href="https://dev.l1x.be/tags/parquet/index.xml" rel="self" type="application/rss+xml"/><item><title>Compressing data with Parquet</title><link>https://dev.l1x.be/posts/2021/03/08/compressing-data-with-parquet/</link><pubDate>Mon, 08 Mar 2021 20:38:21 +0100</pubDate><guid>https://dev.l1x.be/posts/2021/03/08/compressing-data-with-parquet/</guid><description>Abstract Many times I see that people use Sqlite for distributing large datasets. When the use case is analytical (OLAP), there are often better options. We are going to investigate how much better we could do if we use something other than Sqlite. To make sure, I love Sqlite and use it a lot when a simple SQL single file database does it. For this particular use case, I think using Parquet is better suited.</description></item><item><title>Compressing AWS S3 logs after getting HackerNewsed</title><link>https://dev.l1x.be/posts/2020/12/20/compressing-aws-s3-logs-after-getting-hackernewsed/</link><pubDate>Sun, 20 Dec 2020 17:23:21 +0100</pubDate><guid>https://dev.l1x.be/posts/2020/12/20/compressing-aws-s3-logs-after-getting-hackernewsed/</guid><description>Abstract One of my previous articles about Firecracker and RPI got posted on HN, and I just realized that many months ago, I enabled logging on the S3 bucket hosting this content. I quickly wanted to peek into the stats, and when I discovered that Athena could not process compressed S3 logs.
I was already working on a larger AWS codebase in F#, so I decided to write a tool that can download the raw logs from S3 and merge all the small files, convert it to Parquet and upload those back.</description></item></channel></rss>