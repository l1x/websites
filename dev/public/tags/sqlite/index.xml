<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>sqlite on l1x/dev</title><link>https://dev.l1x.be/tags/sqlite/</link><description>Recent content in sqlite on l1x/dev</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 08 Mar 2021 20:38:21 +0100</lastBuildDate><atom:link href="https://dev.l1x.be/tags/sqlite/index.xml" rel="self" type="application/rss+xml"/><item><title>Compressing data with Parquet</title><link>https://dev.l1x.be/posts/2021/03/08/compressing-data-with-parquet/</link><pubDate>Mon, 08 Mar 2021 20:38:21 +0100</pubDate><guid>https://dev.l1x.be/posts/2021/03/08/compressing-data-with-parquet/</guid><description>Abstract Many times I see that people use Sqlite for distributing large datasets. When the use case is analytical (OLAP), there are often better options. We are going to investigate how much better we could do if we use something other than Sqlite. To make sure, I love Sqlite and use it a lot when a simple SQL single file database does it. For this particular use case, I think using Parquet is better suited.</description></item></channel></rss>